{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction\n",
    "\n",
    "### Libraries\n",
    "- http://scikit-learn.org/stable/\n",
    "\n",
    "\n",
    "### Source\n",
    "- https://www.linkedin.com/learning/machine-learning-ai-foundations-value-estimations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import webbrowser\n",
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "# Read the dataset into a data table using Pandas\n",
    "df = pandas.read_csv(\"data/ml_house_data_set.csv\")\n",
    "\n",
    "# Remove the fields from the data set that we don't want to include in our model\n",
    "del df['house_number']\n",
    "del df['unit_number']\n",
    "del df['street_name']\n",
    "del df['zip_code']\n",
    "\n",
    "# Replace categorical data with one-hot encoded data\n",
    "features_df = pandas.get_dummies(df, columns=['garage_type', 'city'])\n",
    "\n",
    "# Remove the sale price from the feature data\n",
    "del features_df['sale_price']\n",
    "\n",
    "# Create the X and y arrays\n",
    "X = features_df.as_matrix()\n",
    "y = df['sale_price'].as_matrix()\n",
    "\n",
    "# Split the data set in a training set (70%) and a test set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "\n",
    "# Fit regression model\n",
    "model = ensemble.GradientBoostingRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=9,\n",
    "    max_features=0.1,\n",
    "    loss='huber',\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Mean Absolute Error: 48727.0015\n",
      "Test Set Mean Absolute Error: 59225.1333\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a file so we can use it in other programs\n",
    "joblib.dump(model, 'models/trained_house_classifier_model.pkl')\n",
    "\n",
    "# Find the error rate on the training set\n",
    "mse = mean_absolute_error(y_train, model.predict(X_train))\n",
    "print(\"Training Set Mean Absolute Error: %.4f\" % mse)\n",
    "\n",
    "# Find the error rate on the test set\n",
    "mse = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(\"Test Set Mean Absolute Error: %.4f\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_New Robinton - 0.00%\n",
      "city_New Michele - 0.00%\n",
      "city_Martinezfort - 0.00%\n",
      "city_Julieberg - 0.00%\n",
      "city_Davidtown - 0.00%\n",
      "city_Lake Jennifer - 0.00%\n",
      "city_Rickytown - 0.01%\n",
      "city_Fosterberg - 0.01%\n",
      "city_East Justin - 0.01%\n",
      "city_West Terrence - 0.01%\n",
      "city_West Brittanyview - 0.01%\n",
      "city_South Stevenfurt - 0.01%\n",
      "city_Joshuafurt - 0.02%\n",
      "city_Leahview - 0.02%\n",
      "city_East Janiceville - 0.02%\n",
      "city_Brownport - 0.03%\n",
      "city_Amystad - 0.03%\n",
      "city_Toddshire - 0.03%\n",
      "city_Wendybury - 0.05%\n",
      "city_Port Adamtown - 0.05%\n",
      "city_Port Daniel - 0.05%\n",
      "city_Clarkberg - 0.09%\n",
      "city_Davidfort - 0.09%\n",
      "city_West Lydia - 0.12%\n",
      "city_Port Jonathanborough - 0.12%\n",
      "garage_type_detached - 0.18%\n",
      "city_Jenniferberg - 0.19%\n",
      "city_East Amychester - 0.20%\n",
      "city_Morrisport - 0.21%\n",
      "city_Lewishaven - 0.22%\n",
      "city_West Gerald - 0.23%\n",
      "city_Richardport - 0.25%\n",
      "city_North Erinville - 0.25%\n",
      "city_East Lucas - 0.27%\n",
      "city_Lake Carolyn - 0.30%\n",
      "has_central_heating - 0.33%\n",
      "city_West Gregoryview - 0.33%\n",
      "city_West Ann - 0.39%\n",
      "city_Lake Dariusborough - 0.43%\n",
      "city_South Anthony - 0.49%\n",
      "has_central_cooling - 0.56%\n",
      "city_Justinport - 0.65%\n",
      "city_Hallfort - 0.66%\n",
      "half_bathrooms - 0.93%\n",
      "garage_type_attached - 0.93%\n",
      "city_Chadstad - 1.12%\n",
      "city_Scottberg - 1.30%\n",
      "stories - 1.46%\n",
      "city_Lake Christinaport - 1.47%\n",
      "city_Lake Jack - 1.59%\n",
      "city_Port Andrealand - 1.59%\n",
      "has_fireplace - 1.86%\n",
      "garage_type_none - 2.04%\n",
      "carport_sqft - 3.35%\n",
      "city_Jeffreyhaven - 3.47%\n",
      "city_Coletown - 4.21%\n",
      "year_built - 4.31%\n",
      "has_pool - 4.40%\n",
      "num_bedrooms - 5.87%\n",
      "full_bathrooms - 9.56%\n",
      "garage_sqft - 12.23%\n",
      "livable_sqft - 15.12%\n",
      "total_sqft - 16.30%\n"
     ]
    }
   ],
   "source": [
    "# Explanation - Features\n",
    "\n",
    "# These are the feature labels from our data set\n",
    "feature_labels = np.array(['year_built', 'stories', 'num_bedrooms', 'full_bathrooms', 'half_bathrooms', 'livable_sqft', 'total_sqft', 'garage_sqft', 'carport_sqft', 'has_fireplace', 'has_pool', 'has_central_heating', 'has_central_cooling', 'garage_type_attached', 'garage_type_detached', 'garage_type_none', 'city_Amystad', 'city_Brownport', 'city_Chadstad', 'city_Clarkberg', 'city_Coletown', 'city_Davidfort', 'city_Davidtown', 'city_East Amychester', 'city_East Janiceville', 'city_East Justin', 'city_East Lucas', 'city_Fosterberg', 'city_Hallfort', 'city_Jeffreyhaven', 'city_Jenniferberg', 'city_Joshuafurt', 'city_Julieberg', 'city_Justinport', 'city_Lake Carolyn', 'city_Lake Christinaport', 'city_Lake Dariusborough', 'city_Lake Jack', 'city_Lake Jennifer', 'city_Leahview', 'city_Lewishaven', 'city_Martinezfort', 'city_Morrisport', 'city_New Michele', 'city_New Robinton', 'city_North Erinville', 'city_Port Adamtown', 'city_Port Andrealand', 'city_Port Daniel', 'city_Port Jonathanborough', 'city_Richardport', 'city_Rickytown', 'city_Scottberg', 'city_South Anthony', 'city_South Stevenfurt', 'city_Toddshire', 'city_Wendybury', 'city_West Ann', 'city_West Brittanyview', 'city_West Gerald', 'city_West Gregoryview', 'city_West Lydia', 'city_West Terrence'])\n",
    "\n",
    "# Load the trained model created with train_model.py\n",
    "model = joblib.load('models/trained_house_classifier_model.pkl')\n",
    "\n",
    "# Create a numpy array based on the model's feature importances\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# Sort the feature labels based on the feature importance rankings from the model\n",
    "feauture_indexes_by_importance = importance.argsort()\n",
    "\n",
    "# Print each feature label, from most important to least important\n",
    "for index in feauture_indexes_by_importance:\n",
    "    print(\"{} - {:.2f}%\".format(feature_labels[index], (importance[index] * 100.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This house has an estimated value of $587,091.02\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "\n",
    "# Load the model we trained previously\n",
    "prediction_model = joblib.load('models/trained_house_classifier_model.pkl')\n",
    "\n",
    "# For the house we want to value, we need to provide the features in the exact same\n",
    "# arrangement as our training data set.\n",
    "house_to_value = [\n",
    "    # House features\n",
    "    2006,   # year_built\n",
    "    1,      # stories\n",
    "    4,      # num_bedrooms\n",
    "    3,      # full_bathrooms\n",
    "    0,      # half_bathrooms \n",
    "    2200,   # livable_sqft\n",
    "    2350,   # total_sqft\n",
    "    0,      # garage_sqft\n",
    "    0,      # carport_sqft\n",
    "    True,   # has_fireplace\n",
    "    False,  # has_pool\n",
    "    True,   # has_central_heating\n",
    "    True,   # has_central_cooling\n",
    "    \n",
    "    # Garage type: Choose only one\n",
    "    0,      # attached\n",
    "    0,      # detached\n",
    "    1,      # none\n",
    "    \n",
    "    # City: Choose only one\n",
    "    0,      # Amystad\n",
    "    1,      # Brownport\n",
    "    0,      # Chadstad\n",
    "    0,      # Clarkberg\n",
    "    0,      # Coletown\n",
    "    0,      # Davidfort\n",
    "    0,      # Davidtown\n",
    "    0,      # East Amychester\n",
    "    0,      # East Janiceville\n",
    "    0,      # East Justin\n",
    "    0,      # East Lucas\n",
    "    0,      # Fosterberg\n",
    "    0,      # Hallfort\n",
    "    0,      # Jeffreyhaven\n",
    "    0,      # Jenniferberg\n",
    "    0,      # Joshuafurt\n",
    "    0,      # Julieberg\n",
    "    0,      # Justinport\n",
    "    0,      # Lake Carolyn\n",
    "    0,      # Lake Christinaport\n",
    "    0,      # Lake Dariusborough\n",
    "    0,      # Lake Jack\n",
    "    0,      # Lake Jennifer\n",
    "    0,      # Leahview\n",
    "    0,      # Lewishaven\n",
    "    0,      # Martinezfort\n",
    "    0,      # Morrisport\n",
    "    0,      # New Michele\n",
    "    0,      # New Robinton\n",
    "    0,      # North Erinville\n",
    "    0,      # Port Adamtown\n",
    "    0,      # Port Andrealand\n",
    "    0,      # Port Daniel\n",
    "    0,      # Port Jonathanborough\n",
    "    0,      # Richardport\n",
    "    0,      # Rickytown\n",
    "    0,      # Scottberg\n",
    "    0,      # South Anthony\n",
    "    0,      # South Stevenfurt\n",
    "    0,      # Toddshire\n",
    "    0,      # Wendybury\n",
    "    0,      # West Ann\n",
    "    0,      # West Brittanyview\n",
    "    0,      # West Gerald\n",
    "    0,      # West Gregoryview\n",
    "    0,      # West Lydia\n",
    "    0       # West Terrence\n",
    "]\n",
    "\n",
    "# scikit-learn assumes you want to predict the values for lots of houses at once, so it expects an array.\n",
    "# We just want to look at a single house, so it will be the only item in our array.\n",
    "homes_to_value = [\n",
    "    house_to_value\n",
    "]\n",
    "\n",
    "# Run the model and make a prediction for each house in the homes_to_value array\n",
    "predicted_home_values = prediction_model.predict(homes_to_value)\n",
    "\n",
    "# Since we are only predicting the price of one house, just look at the first prediction returned\n",
    "predicted_value = predicted_home_values[0]\n",
    "\n",
    "print(\"This house has an estimated value of ${:,.2f}\".format(predicted_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the hyperparameters\n",
    "\n",
    "optimizeModel = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "# Parameters we want to try\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 1000, 3000],\n",
    "    'max_depth': [4, 6],\n",
    "    'min_samples_leaf': [3, 5, 9, 17],\n",
    "    'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "    'max_features': [1.0, 0.3, 0.1],\n",
    "    'loss': ['ls', 'lad', 'huber']\n",
    "}\n",
    "\n",
    "# Define the grid search we want to run. Run it with four cpus in parallel.\n",
    "gs_cv = GridSearchCV(optimizeModel, param_grid, n_jobs=4)\n",
    "\n",
    "# Run the grid search - on only the training data!\n",
    "gs_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the parameters that gave us the best result!\n",
    "print(gs_cv.best_params_)\n",
    "\n",
    "# After running a .....long..... time, the output will be something like\n",
    "# {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_leaf': 9, 'n_estimators': 3000, 'max_features': 0.1, 'max_depth': 6}\n",
    "\n",
    "# That is the combination that worked best.\n",
    "\n",
    "# Find the error rate on the training set using the best parameters\n",
    "mse = mean_absolute_error(y_train, gs_cv.predict(X_train))\n",
    "print(\"Training Set Mean Absolute Error: %.4f\" % mse)\n",
    "\n",
    "# Find the error rate on the test set using the best parameters\n",
    "mse = mean_absolute_error(y_test, gs_cv.predict(X_test))\n",
    "print(\"Test Set Mean Absolute Error: %.4f\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a web page view of the data for easy viewing\n",
    "html = df[0:100].to_html()\n",
    "\n",
    "# Save the html to a temporary file\n",
    "with open(\"output/data.html\", \"w\") as f:\n",
    "    f.write(html)\n",
    "    \n",
    "    # Open the web page in our web browser\n",
    "\n",
    "full_filename = os.path.abspath(\"output/data.html\")\n",
    "webbrowser.open(\"file://{}\".format(full_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
